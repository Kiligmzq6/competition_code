{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:06:42.626955Z",
     "iopub.status.busy": "2023-04-13T05:06:42.626112Z",
     "iopub.status.idle": "2023-04-13T05:07:14.874908Z",
     "shell.execute_reply": "2023-04-13T05:07:14.873605Z",
     "shell.execute_reply.started": "2023-04-13T05:06:42.626859Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting imblearn\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Collecting imbalanced-learn\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/80/911e581a4fc973179e3a48c1272435aa09cce21c12af122c3886d3d35cb5/imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting joblib>=1.1.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/91/d4/3b4c8e5a30604df4c7518c562d4bf0502f2fa29221459226e140cf846512/joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.19.5)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.6.3)\r\n",
      "Collecting scikit-learn>=1.0.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bd/05/e561bc99a615b5c099c7a9355409e5e57c525a108f1c2e156abb005b90a6/scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn, imbalanced-learn, imblearn\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 0.14.1\r\n",
      "    Uninstalling joblib-0.14.1:\r\n",
      "      Successfully uninstalled joblib-0.14.1\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 0.24.2\r\n",
      "    Uninstalling scikit-learn-0.24.2:\r\n",
      "      Successfully uninstalled scikit-learn-0.24.2\r\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0 scikit-learn-1.0.2\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting optuna\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f1/c7/1f351f872584e9e8d731cfedc5199e6f6ace06bb46b560cf7404d47d1439/optuna-3.1.1-py3-none-any.whl (365 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (5.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (1.19.5)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (1.4.41)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (4.64.1)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (1.8.1)\r\n",
      "Collecting cmaes>=0.9.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/a9/83c304855d801dda85c05e6fad0483161ebfba1500efde3de9652b50ac14/cmaes-0.9.1-py3-none-any.whl (21 kB)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from optuna) (4.1.0)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (1.2.2)\r\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (5.9.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (4.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging>=20.0->optuna) (3.0.9)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (4.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\r\n",
      "Installing collected packages: cmaes, optuna\r\n",
      "Successfully installed cmaes-0.9.1 optuna-3.1.1\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting catboost\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/14/5d/0a953bdad818b7b0b794d6002de2af4e9b5b50f532bc938e1cccb78f09ef/catboost-1.1.1-cp37-none-manylinux1_x86_64.whl (76.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (1.1.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (2.2.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (1.19.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (1.6.3)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (0.13)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from catboost) (5.8.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2019.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->catboost) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->catboost) (3.0.9)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from plotly->catboost) (8.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (56.2.0)\r\n",
      "Installing collected packages: catboost\r\n",
      "Successfully installed catboost-1.1.1\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install optuna -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install catboost -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:14.963412Z",
     "iopub.status.busy": "2023-04-13T05:07:14.963130Z",
     "iopub.status.idle": "2023-04-13T05:07:17.645638Z",
     "shell.execute_reply": "2023-04-13T05:07:17.644527Z",
     "shell.execute_reply.started": "2023-04-13T05:07:14.963387Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import BorderlineSMOTE,SMOTE,SMOTENC \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "\n",
    "# 标准化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from scipy.stats import entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:17.648664Z",
     "iopub.status.busy": "2023-04-13T05:07:17.647981Z",
     "iopub.status.idle": "2023-04-13T05:07:18.483630Z",
     "shell.execute_reply": "2023-04-13T05:07:18.481299Z",
     "shell.execute_reply.started": "2023-04-13T05:07:17.648630Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>is_married</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.098182</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.353248</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.021639</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.632453</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>303</td>\n",
       "      <td>11</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.643962</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    income       age  experience_years  is_married  city  region  \\\n",
       "0  train_0  0.098182  0.224138              0.70           0   256       2   \n",
       "1  train_1  0.353248  0.120690              0.55           1     8      12   \n",
       "2  train_2  0.021639  0.551724              0.55           0    75       2   \n",
       "3  train_3  0.632453  0.310345              0.25           1   303      11   \n",
       "4  train_4  0.643962  0.827586              0.90           1    13       7   \n",
       "\n",
       "   current_job_years  current_house_years  house_ownership  car_ownership  \\\n",
       "0           0.500000                 0.00                2              1   \n",
       "1           0.285714                 0.75                2              0   \n",
       "2           0.571429                 0.00                2              0   \n",
       "3           0.357143                 0.25                2              0   \n",
       "4           0.428571                 0.00                2              0   \n",
       "\n",
       "   profession  label  \n",
       "0          18    0.0  \n",
       "1          48    1.0  \n",
       "2           5    0.0  \n",
       "3           3    1.0  \n",
       "4          24    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r'data/data203856/train.csv')\n",
    "test = pd.read_csv(r'data/data203856/test.csv')\n",
    "test['label'] = np.nan\n",
    "data = pd.concat([train,test])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:18.486308Z",
     "iopub.status.busy": "2023-04-13T05:07:18.485661Z",
     "iopub.status.idle": "2023-04-13T05:07:18.675234Z",
     "shell.execute_reply": "2023-04-13T05:07:18.674319Z",
     "shell.execute_reply.started": "2023-04-13T05:07:18.486266Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 240000\r\n",
      "income 40200\r\n",
      "age 59\r\n",
      "experience_years 21\r\n",
      "is_married 2\r\n",
      "city 317\r\n",
      "region 29\r\n",
      "current_job_years 15\r\n",
      "current_house_years 5\r\n",
      "house_ownership 3\r\n",
      "car_ownership 2\r\n",
      "profession 51\r\n",
      "label 2\r\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(i,data[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:18.676755Z",
     "iopub.status.busy": "2023-04-13T05:07:18.676393Z",
     "iopub.status.idle": "2023-04-13T05:07:18.693060Z",
     "shell.execute_reply": "2023-04-13T05:07:18.691784Z",
     "shell.execute_reply.started": "2023-04-13T05:07:18.676726Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_feature = list(data.columns[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:18.694914Z",
     "iopub.status.busy": "2023-04-13T05:07:18.694383Z",
     "iopub.status.idle": "2023-04-13T05:07:18.704300Z",
     "shell.execute_reply": "2023-04-13T05:07:18.703290Z",
     "shell.execute_reply.started": "2023-04-13T05:07:18.694844Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# //求熵\n",
    "def myEntro(x):\n",
    "    \"\"\"\n",
    "        calculate shanno ent of x\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    ent = 0.0\n",
    "    for x_value in x_value_list:\n",
    "        p = float(x[x == x_value].shape[0]) / x.shape[0]\n",
    "        logp = np.log2(p)\n",
    "        ent -= p * logp\n",
    "    #     print(x_value,p,logp)\n",
    "    # print(ent)\n",
    "    return ent\n",
    "\n",
    "    \n",
    "# //求值的范围\n",
    "def myRange(x):\n",
    "    return pd.Series.max(x) - pd.Series.min(x)\n",
    "    \n",
    "feature = ['income', 'age', 'experience_years', 'is_married', 'city',\n",
    "       'region', 'current_job_years', 'current_house_years', 'house_ownership',\n",
    "       'car_ownership', 'profession']\n",
    "    #    , 'current_job_years_precentage',\n",
    "    #    'income_pre_age', 'income_pre_experience_years',\n",
    "    #    'experience_years_pre_age']\n",
    "\n",
    "cat_feature = ['is_married','city','region','house_ownership','car_ownership','profession']\n",
    "#类别特征\n",
    "num_feature = ['income', 'age', 'experience_years', 'current_job_years', 'current_house_years']#,'income_pre_age','income_pre_experience_years','experience_years_pre_age']\n",
    "#连续特征\n",
    "ways = ['mean','max','min','std','sum','median',myEntro,myRange]#,myRms,myMode,myQ25,myQ75,myQ10,myQ90]\n",
    "#进行统计的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:18.706058Z",
     "iopub.status.busy": "2023-04-13T05:07:18.705644Z",
     "iopub.status.idle": "2023-04-13T05:07:41.106931Z",
     "shell.execute_reply": "2023-04-13T05:07:41.105857Z",
     "shell.execute_reply.started": "2023-04-13T05:07:18.706031Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:22<00:00,  3.72s/it]\r\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.46it/s]\r\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.17it/s]\r\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.92it/s]\r\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(cat_feature):\n",
    "    data[cat+\"_\"+\"count\"] =  data.groupby(cat)['id'].transform('count')\n",
    "    feature.append(cat+\"_\"+\"count\")\n",
    "\n",
    "    data[cat+\"_\"+\"label_mean\"] = data.groupby(cat)['label'].transform('mean')\n",
    "    feature.append(cat+\"_\"+\"label_mean\")\n",
    "\n",
    "    for num in num_feature:\n",
    "        for way in ways:\n",
    "            data[num+'_'+cat+\"_\"+str(way)] = data.groupby(cat)[num].transform(way)\n",
    "            feature.append(num+'_'+cat+\"_\"+str(way))\n",
    "\n",
    "\n",
    "num_feature = list(set(feature) - set(cat_feature))\n",
    "for i in tqdm(['income']):\n",
    "    data[i+'_cut'] = pd.cut(data[i],bins=100,labels=range(100)).astype('int')\n",
    "    feature.append(i+'_cut')\n",
    "    cat_feature.append(i+'_cut')\n",
    "\n",
    "for i in tqdm(['age']):\n",
    "    data[i+'_cut'] = pd.cut(data[i],bins=10,labels=range(10)).astype('int')\n",
    "    feature.append(i+'_cut')\n",
    "    cat_feature.append(i+'_cut')\n",
    "\n",
    "for i in tqdm(['experience_years']):\n",
    "    data[i+'_cut'] = pd.cut(data[i],bins=5,labels=range(5)).astype('int')\n",
    "    feature.append(i+'_cut')\n",
    "    cat_feature.append(i+'_cut')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:07:41.108797Z",
     "iopub.status.busy": "2023-04-13T05:07:41.108277Z",
     "iopub.status.idle": "2023-04-13T05:08:01.354716Z",
     "shell.execute_reply": "2023-04-13T05:08:01.353854Z",
     "shell.execute_reply.started": "2023-04-13T05:07:41.108760Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:20<00:00,  2.25s/it]\r\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "num = len(cat_feature)\n",
    "for i in tqdm(range(num)):\n",
    "    for j in range(i,num):\n",
    "        name = str(cat_feature[i])+\"_\"+str(cat_feature[j])\n",
    "        data[name] = data[cat_feature[i]].astype(str) + data[cat_feature[j]].astype(str)\n",
    "        data[name] = enc.fit_transform(data[name]) \n",
    "        feature.append(name)\n",
    "        cat_feature.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:01.357963Z",
     "iopub.status.busy": "2023-04-13T05:08:01.357566Z",
     "iopub.status.idle": "2023-04-13T05:08:51.769652Z",
     "shell.execute_reply": "2023-04-13T05:08:51.768461Z",
     "shell.execute_reply.started": "2023-04-13T05:08:01.357933Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "transfer = StandardScaler()\n",
    "# 调用fit_transform （只需要处理连续特征）\n",
    "num_feature = list(set(feature) - set(cat_feature))\n",
    "data[num_feature] = transfer.fit_transform(data[num_feature])\n",
    "\n",
    "transfer = MinMaxScaler()\n",
    "data[num_feature] = transfer.fit_transform(data[num_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程参考:\n",
    "https://my.oschina.net/u/4295464/blog/4842023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:51.776565Z",
     "iopub.status.busy": "2023-04-13T05:08:51.771136Z",
     "iopub.status.idle": "2023-04-13T05:08:54.361013Z",
     "shell.execute_reply": "2023-04-13T05:08:54.359340Z",
     "shell.execute_reply.started": "2023-04-13T05:08:51.776519Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_feature_list = []\n",
    "for i in feature:\n",
    "    if data[i].nunique()>1:\n",
    "        new_feature_list.append(i)\n",
    "    else:\n",
    "        if i in cat_feature:\n",
    "            cat_feature.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:54.367251Z",
     "iopub.status.busy": "2023-04-13T05:08:54.366239Z",
     "iopub.status.idle": "2023-04-13T05:08:55.381912Z",
     "shell.execute_reply": "2023-04-13T05:08:55.380873Z",
     "shell.execute_reply.started": "2023-04-13T05:08:54.367195Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156000, 313), (84000, 313))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data[data['label'].notna()]\n",
    "test = data[data['label'].isna()]\n",
    "# del data\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:55.383741Z",
     "iopub.status.busy": "2023-04-13T05:08:55.383289Z",
     "iopub.status.idle": "2023-04-13T05:08:55.535350Z",
     "shell.execute_reply": "2023-04-13T05:08:55.517930Z",
     "shell.execute_reply.started": "2023-04-13T05:08:55.383711Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据划分与预处理\n",
    "# feature = set(new_feature_list)\n",
    "X = train[new_feature_list]\n",
    "Y = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:55.552583Z",
     "iopub.status.busy": "2023-04-13T05:08:55.544403Z",
     "iopub.status.idle": "2023-04-13T05:08:56.175813Z",
     "shell.execute_reply": "2023-04-13T05:08:56.167509Z",
     "shell.execute_reply.started": "2023-04-13T05:08:55.552526Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature = new_feature_list\n",
    "X = train[feature]\n",
    "Y = train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:56.191672Z",
     "iopub.status.busy": "2023-04-13T05:08:56.191147Z",
     "iopub.status.idle": "2023-04-13T05:08:56.254706Z",
     "shell.execute_reply": "2023-04-13T05:08:56.253713Z",
     "shell.execute_reply.started": "2023-04-13T05:08:56.191635Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_classification(X, X_test, y, params, num_classes=2,\n",
    "                               folds=None, model_type='lgb',\n",
    "                               eval_metric='logloss', columns=None,\n",
    "                               plot_feature_importance=False,\n",
    "                               model=None, verbose=10000,\n",
    "                               early_stopping_rounds=200,\n",
    "                               splits=None, n_folds=3):\n",
    "    \"\"\"\n",
    "    分类模型函数\n",
    "    返回字典，包括： oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    :params: X - 训练数据， pd.DataFrame\n",
    "    :params: X_test - 测试数据，pd.DataFrame\n",
    "    :params: y - 目标\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - 模型\n",
    "    :params: eval_metric - 评价指标\n",
    "    :params: columns - 特征列\n",
    "    :params: plot_feature_importance - 是否展示特征重要性\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    global y_pred_valid, y_pred\n",
    "\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    splits = folds.split(X, y) if splits is None else splits\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "\n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {\n",
    "        'logloss': {\n",
    "            'lgb_metric_name': 'logloss',\n",
    "            'xgb_metric_name': 'logloss',\n",
    "            'catboost_metric_name': 'Logloss',\n",
    "            'sklearn_scoring_function': metrics.log_loss\n",
    "        },\n",
    "        'lb_score_method': {\n",
    "            'sklearn_scoring_f1': metrics.f1_score,  # 线上评价指标\n",
    "            'sklearn_scoring_accuracy': metrics.accuracy_score,  # 线上评价指标\n",
    "            'sklearn_scoring_auc': metrics.roc_auc_score\n",
    "        },\n",
    "    }\n",
    "    result_dict = {}\n",
    "    count = 0\n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(shape=(len(X), num_classes))\n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(shape=(len(X_test), num_classes))\n",
    "    # list of scores on folds\n",
    "    acc_scores=[]\n",
    "    scores = []\n",
    "    # feature importance\n",
    "    feature_importance = pd.DataFrame()\n",
    "\n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        if verbose:\n",
    "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        # 在此进行数据采样处理\n",
    "        # print(\"采样处理前,正负样本比例为\",Counter(y_train),end = '\\t')\n",
    "        # smo_enn = SMOTENC(categorical_features=[i for i in range(len(feature)) if feature[i] in cat_feature],random_state=2023,n_jobs=-1)\n",
    "        # X_train, y_train = smo_enn.fit_resample(X_train, y_train)\n",
    "        # print(\"采样处理后,正负样本比例为\",Counter(y_train))\n",
    "\n",
    "        if model_type == 'lgb':\n",
    "            model = LGBMClassifier(**params)\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                      verbose=verbose,\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "        if model_type == 'xgb':\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      eval_metric=metrics_dict[eval_metric]['xgb_metric_name'],\n",
    "                      verbose=bool(verbose),  # xgb verbose bool\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)\n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'],\n",
    "                                       **params,\n",
    "                                       loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), \n",
    "                        cat_features=cat_feature, \n",
    "                        # num_features = num_feature,\n",
    "                        #  pairwise_interactions=origin_feature,\n",
    "                        use_best_model=True,\n",
    "                      verbose=False)\n",
    "            # model = BalancedBaggingClassifier(base_estimator=model,\n",
    "            #                     sampling_strategy='auto',\n",
    "            #                     replacement=False,\n",
    "            #                     random_state=0)\n",
    "            # model.fit(X_train, y_train)\n",
    "\n",
    "            y_pre_train = model.predict_proba(X_train)\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "        oof[valid_index] = y_pred_valid\n",
    "        # 评价指标\n",
    "        acc_scores.append(\n",
    "            metrics_dict['lb_score_method']['sklearn_scoring_accuracy'](y_valid, np.argmax(y_pred_valid, axis=1)))\n",
    "        scores.append(\n",
    "            metrics_dict['lb_score_method']['sklearn_scoring_auc'](y_valid, y_pred_valid[:,1]))\n",
    "        print(acc_scores)\n",
    "        print(scores)\n",
    "        # if scores[-1]>0.94:\n",
    "        #     prediction += y_pred\n",
    "        #     count = count+1\n",
    "        prediction += y_pred\n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "        if model_type == 'xgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    prediction /= n_splits\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['acc_scores'] = acc_scores\n",
    "    result_dict['scores'] = scores\n",
    "\n",
    "\n",
    "    if model_type == 'lgb' or model_type == 'xgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12))\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "            plt.title('LGB Features (avg over folds)')\n",
    "            plt.show()\n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"train_model_classification cost time:{}\".format(end_time - start_time))\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T05:08:56.256507Z",
     "iopub.status.busy": "2023-04-13T05:08:56.256092Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类个数num_classes:2\r\n",
      "Fold 1 started at Thu Apr 13 13:08:56 2023\r\n",
      "[0.9032051282051282]\r\n",
      "[0.940374324805705]\r\n",
      "Fold 2 started at Thu Apr 13 13:11:27 2023\r\n",
      "[0.9032051282051282, 0.9058333333333334]\r\n",
      "[0.940374324805705, 0.9433745066510744]\r\n",
      "Fold 3 started at Thu Apr 13 13:14:55 2023\r\n",
      "[0.9032051282051282, 0.9058333333333334, 0.9024358974358975]\r\n",
      "[0.940374324805705, 0.9433745066510744, 0.9367520694627971]\r\n",
      "Fold 4 started at Thu Apr 13 13:17:20 2023\r\n",
      "[0.9032051282051282, 0.9058333333333334, 0.9024358974358975, 0.9044871794871795]\r\n",
      "[0.940374324805705, 0.9433745066510744, 0.9367520694627971, 0.9416194244693141]\r\n",
      "Fold 5 started at Thu Apr 13 13:20:37 2023\r\n",
      "[0.9032051282051282, 0.9058333333333334, 0.9024358974358975, 0.9044871794871795, 0.9055769230769231]\r\n",
      "[0.940374324805705, 0.9433745066510744, 0.9367520694627971, 0.9416194244693141, 0.9405878127004588]\r\n",
      "Fold 6 started at Thu Apr 13 13:24:13 2023\r\n",
      "[0.9032051282051282, 0.9058333333333334, 0.9024358974358975, 0.9044871794871795, 0.9055769230769231, 0.9019230769230769]\r\n",
      "[0.940374324805705, 0.9433745066510744, 0.9367520694627971, 0.9416194244693141, 0.9405878127004588, 0.9378354914113705]\r\n",
      "Fold 7 started at Thu Apr 13 13:26:42 2023\r\n",
      "[0.9032051282051282, 0.9058333333333334, 0.9024358974358975, 0.9044871794871795, 0.9055769230769231, 0.9019230769230769, 0.9071153846153847]\r\n",
      "[0.940374324805705, 0.9433745066510744, 0.9367520694627971, 0.9416194244693141, 0.9405878127004588, 0.9378354914113705, 0.9418489996834368]\r\n",
      "Fold 8 started at Thu Apr 13 13:29:42 2023\r\n"
     ]
    }
   ],
   "source": [
    "cat_params = {'learning_rate': 0.1, 'depth': 9, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',#'task_type': 'GPU',\n",
    "              'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "\n",
    "n_fold = 10\n",
    "num_classes = 2\n",
    "print(\"分类个数num_classes:{}\".format(num_classes))\n",
    "folds = StratifiedKFold(n_splits=n_fold, random_state=1314, shuffle=True)\n",
    "\n",
    "\n",
    "result_dict_cat = train_model_classification(X=X,\n",
    "                                             X_test=test[feature],\n",
    "                                             y=Y,\n",
    "                                             params=cat_params,\n",
    "                                             num_classes=num_classes,\n",
    "                                             folds=folds,\n",
    "                                             model_type='cat',\n",
    "                                             eval_metric='logloss',\n",
    "                                             plot_feature_importance=True,\n",
    "                                             verbose=1,\n",
    "                                             early_stopping_rounds=800,#原400\n",
    "                                             n_folds=n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T03:46:48.871381Z",
     "iopub.status.busy": "2023-04-13T03:46:48.870575Z",
     "iopub.status.idle": "2023-04-13T03:46:49.137898Z",
     "shell.execute_reply": "2023-04-13T03:46:49.136985Z",
     "shell.execute_reply.started": "2023-04-13T03:46:48.871344Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('cat_sub_5cv_cut.csv')\n",
    "sub['label'] = result_dict_cat['prediction'][:, 1]\n",
    "sub[['id','label']].to_csv('cat_sub_10cv.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.9395127068770044\n",
    "\n",
    "Fold 5 started at Thu Apr  6 10:02:58 2023\n",
    "\n",
    "[0.8665384615384616, 0.8759294871794872, 0.8741346153846153, 0.8936858974358974, 0.9008012820512821]\n",
    "\n",
    "[0.9079589677791218, 0.9277018656813405, 0.9215184274669903, 0.9364011520096265, 0.9361199423063424]\n",
    "\n",
    "CV mean score: 0.9259, std: 0.0106.\n",
    "\n",
    "### 0.9405441328372578\n",
    "\n",
    "[0.903301282051282, 0.9008333333333334, 0.9008974358974359, 0.9055448717948718, 0.9026923076923077]\n",
    "\n",
    "[0.9400705898728445, 0.9370555695899808, 0.9374504526928386, 0.9419737474623144, 0.9400199148017934]\n",
    "\n",
    "CV mean score: 0.9393, std: 0.0018.\n",
    "\n",
    "### 0.9406685678115321\n",
    "\n",
    "[0.9053846153846153, 0.901474358974359, 0.9013461538461538, 0.9040384615384616, 0.9021794871794871]\n",
    "\n",
    "[0.9400077373638717, 0.9374313607312934, 0.9378180336715911, 0.9412380521299796, 0.9394537118933349]\n",
    "\n",
    "CV mean score: 0.9392, std: 0.0014.\n",
    "\n",
    "[0.9362484888771758, 0.9382271433098509, 0.940827013838387, 0.9414658352487052, 0.9340132236489217, 0.9360767036876199, 0.9419637379298802, 0.939804305116714, 0.9423374126345797, 0.934654941171575, 0.9370173304886397, 0.9335991557984971, 0.9371071861845076, 0.9439558059354756, 0.9435747136939572, 0.9435345851608188, 0.938556971856725, 0.942038331505848, 0.9387929459064328, 0.938846780579922]\n",
    "[0.9370931057436157, 0.9408271472119812, 0.9361387795691163, 0.940195185015088, 0.939051580227943, 0.935351245202654, 0.9391370534419747, 0.9429832528492308, 0.9397600289999494, 0.94030431130472]\n",
    "CV mean score: 0.9391, std: 0.0022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500early\n",
    "\n",
    "[0.9020192307692307, 0.9015064102564102, 0.9009935897435898, 0.9035897435897436, 0.9016346153846154]\n",
    "\n",
    "[0.9384516829695065, 0.936771090314636, 0.9364218869561385, 0.9407541573401077, 0.9392777185843183]\n",
    "\n",
    "CV mean score: 0.9383, std: 0.0016.\n",
    "\n",
    "MaxMin\n",
    "[0.9395301859246554, 0.9373190948541511, 0.9368598924615383, 0.9411030130525107, 0.9390176328117195]\n",
    "CV mean score: 0.9388, std: 0.0015.\n",
    "\n",
    "只用income分箱\n",
    "\n",
    "[0.9044551282051282, 0.9023717948717949, 0.90125, 0.9046794871794872, 0.9012820512820513]\n",
    "\n",
    "[0.939636175122996, 0.9377035723855507, 0.9373895336676241, 0.9415378468825828, 0.9393120754644683]\n",
    "\n",
    "CV mean score: 0.9391, std: 0.0015.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
